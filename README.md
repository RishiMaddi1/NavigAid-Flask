
🚀 **NavigAid**  
A multimodal app for image analysis, speech translation, and vision-based QA, powered by Groq and Cloudinary.

📌 **Problem Statement**  
Problem Statement 7 – Transform the Future of Rural Commerce

🎯 **Objective**  
NavigAid solves the problem of providing vision and speech-based interaction for users to upload images and audio, ask questions, and receive AI-driven answers. The app is especially useful in situations where users have limited text-based interfaces and need a seamless multimodal experience. The target audience includes individuals with visual or auditory impairments, as well as users in rural areas with limited access to advanced tech.

🧠 **Team & Approach**  
**Team Name**: NavigAid Team

**Team Members**:  
- Rishi (Lead Developer)  
- Arhat 
- Vennela 

**Your Approach**:  
- **Why you chose this problem**: We saw the potential of combining image analysis and speech translation in one app to help users access information seamlessly.  
- **Key challenges you addressed**: Integrating real-time image analysis and speech-based question answering while ensuring smooth interaction between front-end and back-end.  
- **Any pivots, brainstorms, or breakthroughs during hacking**: We experimented with using Groq's AI services to handle both image and speech processing effectively, creating a unique value proposition for rural and underserved populations.

🛠️ **Tech Stack**  
**Core Technologies Used**:  
- **Frontend**: Flutter  
- **Backend**: Python (Flask)  
- **Database**: None (API-driven data fetching)  
- **APIs**: Cloudinary, Groq AI  
- **Hosting**: Heroku  

**Sponsor Technologies Used** (if any):  
- **Groq**: Used for AI-based image analysis and speech-to-text translation.

✨ **Key Features**  
Highlight the most important features of your project:

✅ **Image Upload & Analysis**: Upload an image to be analyzed, and receive a structured description of the content.  
✅ **Speech Translation**: Upload an audio file containing a question, which will be converted into text.  
✅ **Vision-based QA**: Ask questions based on the context of the uploaded image and receive AI-generated answers.  
✅ **Text-to-Speech**: Answers are returned as speech for accessibility.

📽️ **Demo & Deliverables**  
Demo Video Link: [Paste YouTube or Loom link here]  
Pitch Deck / PPT Link: [Paste Google Slides / PDF link here]  

✅ **Tasks & Bonus Checklist**  
- All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form (Details in Participant Manual)  
- All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points) (Details in Participant Manual)  
- All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points) (Details in Participant Manual)  

🧪 **How to Run the Project**  
**Requirements**:  
- Android Device (to install APK)  
- Cloudinary and Groq API keys  

**Local Setup** (for developers):  
1. Clone the repo  
   ```bash
   git clone https://github.com/your-team/project-name
   ```

2. Install dependencies  
   ```bash
   cd backend-directory
   pip install -r requirements.txt
   ```

3. Set environment variables for API keys (Cloudinary, Groq).  
4. Start the backend server  
   ```bash
   python app.py
   ```

**APK Installation**:  
- Download the APK file: [app-release.apk](https://github.com/your-repo-url)  
- Install on your Android device and start using the app.

🧬 **Future Scope**  
List improvements, extensions, or follow-up features:

📈 **More integrations**: Integration with more image analysis tools and voice processing APIs.  
🛡️ **Security enhancements**: Adding encryption for user-uploaded content.  
🌐 **Localization / broader accessibility**: Adding multilingual support and voice-based interaction for global reach.

📎 **Resources / Credits**  
- **Cloudinary** for image storage.  
- **Groq** for AI models in vision and speech.  
- **Flutter** for mobile app development.  
- **Flask** for backend development.

🏁 **Final Words**  
Our hackathon journey was challenging but rewarding. We faced difficulties integrating real-time processing but solved them by experimenting with different API setups. Shout-out to our team for their hard work and creative solutions!

```

This version follows the structure you provided and includes all relevant sections such as objectives, tech stack, key features, demo, future scope, and credits.
